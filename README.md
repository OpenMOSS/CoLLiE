<div align="center">
 <img src="docs/assets/images/banner.png">
</div>

# CoLLiE

CoLLiE (Collaborative Tuning of Large Language Models in an Efficient Way)ï¼Œä¸€ä¸ªå¸®åŠ©æ‚¨ä»é›¶å¼€å§‹è®­ç»ƒå¤§æ¨¡å‹çš„å®Œæ•´å·¥å…·ç®±ã€‚


[![Github Repo Stars](https://img.shields.io/github/stars/openlmlab/collie?style=social)](https://github.com/openlmlab/collie/stargazers)
[![GitHub](https://img.shields.io/github/license/OpenLMLab/collie)]()
[![Doc](https://img.shields.io/badge/Website-Doc-blue)](https://openlmlab-collie.readthedocs.io/zh_CN/latest/)
[![HuggingFace badge](https://img.shields.io/badge/%F0%9F%A4%97HuggingFace-Join-yellow)](https://huggingface.co/openlmlab)
[![GitHub Workflow Status (with event)](https://img.shields.io/github/actions/workflow/status/OpenLMLab/collie/python-publish.yml)](https://pypi.org/project/collie-lm/)
[![GitHub commit activity (branch)](https://img.shields.io/github/commit-activity/w/OpenLMLab/collie)](https://github.com/OpenLMLab/collie/commits/main)
[![GitHub issues](https://img.shields.io/github/issues/OpenLMLab/collie)](https://github.com/OpenLMLab/collie/issues)

<h4 align="center">
  <p>
     [ <a href="https://github.com/OpenLMLab/collie/blob/dev/README.md">ç®€ä½“ä¸­æ–‡</a> ] |
     [ <a href="https://github.com/OpenLMLab/collie/blob/dev/README_EN.md">English</a> ]
  </p>
</h4>


## æ–°é—»
* [2023/07/18] å‘å¸ƒPythonåŒ…`collie-lm`ã€‚æ‚¨å¯ä»¥åœ¨[é“¾æ¥](https://pypi.org/project/collie-lm/#history)ä¸­æŸ¥çœ‹æ›´å¤šç»†èŠ‚ï¼

## ç›®å½•
<ul>
    <li><a href="#ä¸ºä»€ä¹ˆé€‰æ‹©CoLLiE">ä¸ºä»€ä¹ˆé€‰æ‹©CoLLiE</a></li>
    <li><a href="#ç‰¹æ€§">ç‰¹æ€§</a></li>
    <li><a href="#CoLLiEæ”¯æŒçš„æ¨¡å‹">CoLLiEæ”¯æŒçš„æ¨¡å‹</a></li>
    <li><a href="#è¯„æµ‹">è¯„æµ‹</a></li>
    <li><a href="#å®‰è£…">å®‰è£…</a></li>
    <li><a href="#Dockerå®‰è£…">Dockerå®‰è£…</a></li>
    <li><a href="#ä½¿ç”¨">ä½¿ç”¨</a>
        <ul>
            <li><a href="#å¿«é€Ÿå¼€å§‹">å¿«é€Ÿå¼€å§‹</a></li>
            <li><a href="#æœ‰è¶£çš„æ’ä»¶">æœ‰è¶£çš„æ’ä»¶</a></li>
            <li><a href="#æ›´å¤šæˆåŠŸæ ·ä¾‹å’Œå®Œæ•´æ•™ç¨‹">æ›´å¤šæˆåŠŸæ ·ä¾‹å’Œå®Œæ•´æ•™ç¨‹</a></li>
        </ul>
    </li>
    <li><a href="#ç¤¾åŒº">ç¤¾åŒº</a></li>
    <li><a href="#è´¡çŒ®è€…">è´¡çŒ®è€…</a></li>
    <li><a href="#å¼•ç”¨æˆ‘ä»¬">å¼•ç”¨æˆ‘ä»¬</a></li>
</ul>

## ä¸ºä»€ä¹ˆé€‰æ‹©CoLLiE
CoLLiEæ˜¯ä¸€ä¸ªå¯ä»¥å¸®åŠ©æ‚¨ä»é›¶å¼€å§‹è®­ç»ƒå¤§æ¨¡å‹çš„å®Œæ•´å·¥å…·ç®±ï¼Œå®ƒæä¾›äº†æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹å¾®è°ƒã€æ¨¡å‹ä¿å­˜ä»¥åŠè®­ç»ƒè¿‡ç¨‹å„é¡¹æŒ‡æ ‡ç›‘æµ‹ç­‰åŠŸèƒ½ã€‚CoLLiEé›†æˆäº†ç°æœ‰çš„å¹¶è¡Œç­–ç•¥ã€é«˜æ•ˆå‚æ•°å¾®è°ƒæ–¹æ³•å’Œé«˜æ•ˆä¼˜åŒ–å™¨ï¼Œä»¥åŠ å¿«è®­ç»ƒçš„é€Ÿåº¦ï¼Œæé«˜è®­ç»ƒçš„è´¨é‡ï¼Œé™ä½è®­ç»ƒçš„å¼€é”€ã€‚CoLLiEæ”¯æŒä¸»æµçš„å¤šç§æ¨¡å‹ï¼ˆå¦‚MOSS, InternLM, LLaMA, ChatGLMç­‰ï¼‰ï¼Œæ‚¨å¯ä»¥è½»æ¾åœ¨ä¸åŒçš„æ¨¡å‹ä¹‹é—´åˆ‡æ¢ã€‚æ­¤å¤–ï¼ŒCoLLiEæä¾›äº†ä¸°å¯Œçš„æ–‡æ¡£ï¼Œä½¿åˆå­¦è€…å¯ä»¥å¿«é€Ÿå…¥é—¨ã€‚åŒæ—¶ï¼ŒCoLLiEè¿˜æä¾›äº†é«˜åº¦å¯å®šåˆ¶åŒ–çš„åŠŸèƒ½å’Œçµæ´»çš„é…ç½®é€‰é¡¹ï¼Œä½¿æœ‰ç»éªŒçš„ç”¨æˆ·èƒ½å¤Ÿæ ¹æ®è‡ªå·±çš„éœ€æ±‚è¿›è¡Œä¸ªæ€§åŒ–å®šåˆ¶ã€‚æ— è®ºæ‚¨æ˜¯åˆå­¦è€…è¿˜æ˜¯æœ‰ç»éªŒçš„ä¸“ä¸šäººå£«ï¼ŒCoLLiEéƒ½å¯ä»¥ä¸ºæ‚¨æä¾›æ»¡è¶³éœ€æ±‚çš„è§£å†³æ–¹æ¡ˆã€‚

## ç‰¹ç‚¹

CoLLiE åŸºäº *DeepSpeed* å’Œ *PyTorch*ï¼Œä¸ºå¤§å‹è¯­è¨€æ¨¡å‹æä¾›åä½œå¼å’Œé«˜æ•ˆçš„è°ƒä¼˜æ–¹æ³•ã€‚
å®ƒä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å››ä¸ªç‰¹ç‚¹ï¼š

<div align="center">
    <img src="docs/assets/images/feature_list.png" width="800px">
</div>

- å¹¶è¡Œç­–ç•¥
  - æ•°æ®å¹¶è¡Œ (DP)
  - [æµæ°´çº¿å¹¶è¡Œ (PP)](https://arxiv.org/pdf/1811.06965.pdf)
  - [å¼ é‡å¹¶è¡Œ (TP)](https://arxiv.org/pdf/2104.04473.pdf)
  - [é›¶å†—ä½™ä¼˜åŒ–å™¨ (ZeRO)](https://arxiv.org/pdf/1910.02054.pdf)
- é«˜æ•ˆå¾®è°ƒ
  - [LOMO](https://arxiv.org/pdf/2306.09782.pdf)
  - [LoRA](https://arxiv.org/pdf/2106.09685.pdf)
  - [Flash Attention](https://arxiv.org/pdf/2205.14135.pdf)
- è®¾è®¡ä¼˜é›…
- ç”¨æˆ·å‹å¥½

<details>
  <summary>å®Œæ•´ç‰¹æ€§</summary>
  <div align="center">
      <img src="docs/assets/images/features.svg" width="800px">
  </div>
</details>

## CoLLiEæ”¯æŒçš„æ¨¡å‹
- [MOSS-MOON](https://github.com/OpenLMLab/MOSS)
    - [moss-moon-003-base](https://huggingface.co/fnlp/moss-moon-003-base)
    - [moss-moon-003-sft](https://huggingface.co/fnlp/moss-moon-003-sft)
    - [moss-moon-003-sft-plugin](https://huggingface.co/fnlp/moss-moon-003-sft-plugin)
- [InternLM](https://github.com/InternLM/InternLM)
    - [internlm-7b](https://huggingface.co/internlm/internlm-7b)
    - [internlm-chat-7b](https://huggingface.co/internlm/internlm-chat-7b)
    - [internlm-chat-7b-8k](https://huggingface.co/internlm/internlm-chat-7b-8k)
- [LLaMA](https://github.com/facebookresearch/llama)
    - [llama-7b-hf](https://huggingface.co/decapoda-research/llama-7b-hf)
    - [llama-13b-hf](https://huggingface.co/decapoda-research/llama-13b-hf)
    - [llama-30b-hf](https://huggingface.co/decapoda-research/llama-30b-hf)
    - [llama-65b-hf](https://huggingface.co/decapoda-research/llama-65b-hf)
- [LLaMA-2](https://github.com/facebookresearch/llama)
    - [Llama-2-7b-hf](https://huggingface.co/meta-llama/Llama-2-7b-hf)
    - [Llama-2-13b-hf](https://huggingface.co/meta-llama/Llama-2-13b-hf)
    - [Llama-2-70b-hf](https://huggingface.co/meta-llama/Llama-2-70b-hf)
    - [Llama-2-7b-chat-hf](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf)
    - [Llama-2-13b-chat-hf](https://huggingface.co/meta-llama/Llama-2-13b-chat-hf)
    - [Llama-2-70b-chat-hf](https://huggingface.co/meta-llama/Llama-2-70b-chat-hf)
- [OpenLLaMA](https://github.com/openlm-research/open_llama)
    - [open_llama_3b](https://huggingface.co/openlm-research/open_llama_3b)
    - [open_llama_7b](https://huggingface.co/openlm-research/open_llama_7b)
    - [open_llama_13b](https://huggingface.co/openlm-research/open_llama_13b)
    - [open_llama_7b_v2](https://huggingface.co/openlm-research/open_llama_7b_v2)
- [ChatGLM](https://github.com/THUDM/ChatGLM-6B)
    - [chatglm-6b](https://huggingface.co/THUDM/chatglm-6b)
- [ChatGLM2](https://github.com/THUDM/ChatGLM2-6B)
    - [chatglm2-6b](https://huggingface.co/THUDM/chatglm2-6b)


## è¯„æµ‹

### ååé‡
|            | 7B   | 13B  | 30B  | 65B  |
| ---------- | ---- | ---- | ---- | ---- |
| Finetune   | 2    | 3    | 6    | 16   |
| LoRA       | 1    | 1    | 1    | 2    |
| LOMO       | 1    | 1    | 1    | 2    |

æ³¨ï¼šåœ¨ä½¿ç”¨Adamä¼˜åŒ–å™¨çš„æƒ…å†µä¸‹ï¼Œå„ä¸ªæ¨¡å‹éœ€è¦çš„æœ€å°‘çš„GPUï¼ˆA100ï¼‰æ•°é‡

## å®‰è£…
åœ¨å®‰è£…å‰ï¼Œä½ éœ€è¦ç¡®ä¿ï¼š
* PyTorch >= 1.13
* CUDA >= 11.6 
* Linux OS
### PyPIå®‰è£…
ä½ å¯ä»¥ç®€å•åœ°é€šè¿‡PyPIå®‰è£…ï¼Œå‘½ä»¤å¦‚ä¸‹ï¼š
```bash
pip install collie-lm
```
### æºç å®‰è£…
```bash
git clone https://github.com/OpenLMLab/collie
python setup.py install
```

## Dockerå®‰è£…

## ä½¿ç”¨

### å¿«é€Ÿå¼€å§‹

ä¸‹é¢å°†æä¾›ä¸€ä¸ªä½¿ç”¨CoLLiEè®­ç»ƒMossçš„æ ·ä¾‹ï¼ŒåŒæ—¶ä½¿ç”¨LOMOä¼˜åŒ–å™¨ï¼Œå¹¶ä¸”å¼€å¯ZeRO3æ¥é™ä½æ˜¾å­˜æ¶ˆè€—ã€‚

é‚£ä¹ˆï¼Œè¯·æŒ‰ç…§ä¸‹é¢çš„æ­¥éª¤å¼€å¯ä½ çš„å¤§æ¨¡å‹è®­ç»ƒä¹‹æ—…å§~ 
<img src="docs/assets/images/mario-running.gif" height="50px"/>

#### ç¬¬ä¸€æ­¥ï¼šå¯¼å…¥å¿…è¦çš„åŒ…
```python
from transformers import AutoTokenizer
from collie.config import CollieConfig
from collie.data import CollieDatasetForTraining
from collie.data import CollieDataLoader
from collie.optim.lomo import Lomo
from collie.controller.trainer import Trainer
from collie.controller.evaluator import EvaluatorForPerplexity, EvaluatorForGeneration
from collie.models.moss_moon import Moss003MoonForCausalLM
from collie.utils.monitor import StepTimeMonitor, TGSMonitor, MemoryMonitor, LossMonitor, EvalMonitor
from collie.metrics import DecodeMetric, PPLMetric
from collie.module import GPTLMLoss
from collie.utils.data_provider import GradioProvider
```

#### ç¬¬äºŒæ­¥ï¼šè®¾ç½®è·¯å¾„
é€‰æ‹©é¢„è®­ç»ƒæ¨¡å‹ä¸ºMOSS
```
pretrained_model = "fnlp/moss-moon-003-sft"
```

#### ç¬¬ä¸‰æ­¥ï¼šè®¾ç½®CoLLiEé…ç½®
```python
config = CollieConfig.from_pretrained(pretrained_model, trust_remote_code=True)
# å¼ é‡å¹¶è¡Œ
config.tp_size = 2
# æ•°æ®å¹¶è¡Œ
config.dp_size = 1
# æµæ°´çº¿å¹¶è¡Œ
config.pp_size = 1
# è®­ç»ƒçš„epochæ•°é‡
config.train_epochs = 1
# æ¯{100}ä¸ªstepè¿›è¡Œä¸€æ¬¡eval
config.eval_per_n_steps = 100
# æ¯{1}ä¸ªepochè¿›è¡Œä¸€æ¬¡eval
config.eval_per_n_epochs = 1 
# æ¯ä¸ªGPUçš„batch_sizeè®¾ç½®ä¸º{16}
config.train_micro_batch_size = 16
# æ¯æ¬¡evalçš„batch_sizeä¸º{1}
config.eval_batch_size = 1
# è®¾ç½®DeepSpeedé…ç½®
config.ds_config = {
        # å¼€å¯FP16
        "fp16": {
            "enabled": True
        },
        "zero_allow_untested_optimizer": True,
        "zero_force_ds_cpu_optimizer": False,
        # å¼€å¯ZeRO-3
        "zero_optimization": {
            "stage": 3,
            "offload_optimizer": {
                "device": "cpu",
                "pin_memory": False
            }
        },
        "monitor_config": {
            "enabled": True,
            "tag": "adan",
            "csv_monitor": {
                "enabled": True,
                "output_path": "./ds_logs/"
            }
        }
}
```

#### ç¬¬å››æ­¥ï¼šè®¾ç½®Tokenizer
```python
tokenizer = AutoTokenizer.from_pretrained("fnlp/moss-moon-003-sft", trust_remote_code=True)
```

#### ç¬¬äº”æ­¥ï¼šåŠ è½½æ•°æ®é›†
è¿™é‡Œè‡ªå®šä¹‰ä¸€ä¸ªæ•°æ®é›†ï¼Œæ•°æ®æ ¼å¼å¯ä»¥æä¾›ä¸¤ç§å½¢å¼ï¼Œå…·ä½“è¯·å‚è€ƒæ–‡æ¡£ã€‚
```python
train_dataset = [
    {
        'input': 'Collie is a python package for ',
        'output': 'finetuning large language models.'
    } for _ in range(10000)
]
train_dataset = CollieDatasetForTraining(train_dataset, tokenizer)
eval_dataset = train_dataset[:32]
```

#### ç¬¬å…­æ­¥ï¼šåŠ è½½é¢„è®­ç»ƒæ¨¡å‹
```python
model = Moss003MoonForCausalLM.from_pretrained(pretrained_model, config=config)
```

#### ç¬¬ä¸ƒæ­¥ï¼šè®¾ç½®ä¼˜åŒ–å™¨
```python
optimizer = Lomo(
    model,
    lr = 0.001,
    clip_grad_norm = 5.0
)
```

#### ç¬¬å…«æ­¥ï¼šæ·»åŠ ç›‘è§†å™¨
```python
monitors = [
    # æ¯ä¸ªstepç”¨æ—¶ç›‘æµ‹
    StepTimeMonitor(config),
    # TGSï¼ˆæ¯ç§’ç”Ÿæˆtokenæ•°é‡ç›‘æµ‹ï¼‰
    TGSMonitor(config),
    # æ˜¾å­˜ä½¿ç”¨æƒ…å†µç›‘æµ‹
    MemoryMonitor(config),
    # Losså€¼ç›‘æµ‹
    LossMonitor(config),
    # Evalç»“æœç›‘æµ‹
    EvalMonitor(config)
]
```

#### ç¬¬ä¹æ­¥ï¼šæ·»åŠ Evaluator
è¿™é‡Œæ·»åŠ ä¸¤ä¸ªEvaluatorï¼Œåˆ†åˆ«ç”¨äºè®¡ç®—PPL(å›°æƒ‘åº¦ï¼šPerplexity)å’Œä¿å­˜Decodeç»“æœã€‚
```python
evaluator_ppl = EvaluatorForPerplexity(
    model = model,
    config = config,
    dataset = eval_dataset,
    monitors = [
        EvalMonitor(config)
    ],
    metrics = {
        'ppl': PPLMetric()
    }
)
evaluator_decode = EvaluatorForGeneration(
    model = model,
    config = config,
    tokenizer = tokenizer,
    dataset = eval_dataset,
    monitors = [
        EvalMonitor(config)
    ],
    metrics = {
        'decode': DecodeMetric()
    }

)
```

#### ç¬¬åæ­¥ï¼šå®ä¾‹åŒ–Trainer
```python
trainer = Trainer(
    model = model,
    config = config,
    loss_fn = GPTLMLoss(-100),
    optimizer = optimizer,
    train_dataset = train_dataset,
    monitors = monitors,
    evaluators = [evaluator_ppl, evaluator_decode],
)
# å¼€å§‹è®­ç»ƒ/éªŒè¯
trainer.train()
```

#### æœ€åä¸€æ­¥ï¼šå¯åŠ¨å‘½ä»¤è¡Œï¼Œå¼€å§‹è®­ç»ƒï¼ğŸ‘
```bash
Command CUDA_VISIBLE_DEVICES=0,1,2,3 torchrun --rdzv_backend=c10d --rdzv_endpoint=localhost:29402 --nnodes=1 --nproc_per_node=4 finetune_moss_for_training.py
```
å¦‚æœä½ çš„å‘½ä»¤è¡Œå‡ºç°å¦‚ä¸‹çš„è¿›åº¦æ¡ï¼Œé‚£ä¹ˆæ­å–œä½ ï¼Œä½ å·²ç»æˆåŠŸå¼€å§‹è®­ç»ƒä½ çš„å¤§æ¨¡å‹ï¼
<div align="center">
 <img src="docs/assets/images/progress.png">
</div>

å®Œæ•´ä»£ç è¯·å‚è€ƒ<a href="https://github.com/OpenLMLab/collie/blob/dev/examples/finetune_moss_for_training.py">examples/finetune_moss_for_training.py</a>ã€‚

### æœ‰è¶£çš„æ’ä»¶

CoLLiEæä¾›äº†è®¸å¤šå³æ’å³ç”¨çš„æ’ä»¶ï¼Œä¸‹é¢å°†ä»‹ç»Monitoræ£€æµ‹å™¨å’Œå¼‚æ­¥DataProviderï¼Œæ›´å¤šæ’ä»¶ç­‰å¾…æ¢ç´¢å’Œå¼€å‘...

#### Monitorç›‘æµ‹å™¨
åœ¨CollieConfig.ds_configä¸­æ·»åŠ monitoré…ç½®ï¼Œå¹¶åœ¨Trainerä¸­å¯ç”¨å³å¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ‰“å¼€ç›‘æµ‹å™¨ã€‚
```python
    "monitor_config": {
        # å¼€å¯æ£€æµ‹å™¨
        "enabled": True,
        # ä¿å­˜çš„æ–‡ä»¶åå‰ç¼€
        "tag": "adan",
        # ä¿å­˜æ–‡ä»¶æ ¼å¼:csv
        "csv_monitor": {
            "enabled": True,
            # ä¿å­˜æ–‡ä»¶å¤¹
            "output_path": "./ds_logs/"
        }
    }
```
å¯ç”¨æ£€æµ‹å™¨åï¼Œä½ å°†åœ¨`ds_logs`æ–‡ä»¶å¤¹ä¸­è·å–ç›¸å…³çš„æ–‡ä»¶ï¼Œå¦‚ï¼š
<div align="center">
 <img src="docs/assets/images/monitor.png">
</div>

#### å¼‚æ­¥DataProvider
ä½ åªéœ€è¦åœ¨Trainerä¸­æ·»åŠ ï¼šdata_providerï¼Œå³å¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ‰“å¼€ä¸€ä¸ªå¼‚æ­¥DataProviderï¼Œæ–¹ä¾¿åŠæ—¶Human Evalï¼
```python
trainer = Trainer(
    model = model,
    config = config,
    loss_fn = GPTLMLoss(-100),
    optimizer = optimizer,
    train_dataset = train_dataset,
    monitors = monitors,
    evaluators = [evaluator_ppl, evaluator_decode],
    # æ·»åŠ 
    data_provider = GradioProvider(tokenizer)
)
```
<div align="center">
 <img src="docs/assets/images/data_provider.png">
</div>



### æ›´å¤šæˆåŠŸæ ·ä¾‹å’Œå®Œæ•´æ•™ç¨‹
CoLLiEæä¾›äº†å®Œæ•´çš„ [æ•™ç¨‹](https://openlmlab-collie.readthedocs.io/zh_CN/latest/)ã€‚ æ›´å¤šçš„ç¤ºä¾‹ä¹Ÿå¯åœ¨ [ç¤ºä¾‹](examples) ä¸­æŸ¥çœ‹ã€‚

## ç¤¾åŒº

## è´¡çŒ®è€…
<a href="https://github.com/Openlmlab/collie/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=Openlmlab/collie" />
</a>

## å¼•ç”¨æˆ‘ä»¬
