[**ä¸­æ–‡**](./README.md) | [**English**](./README_EN.md)

# CoLLiE
<div align="center">
 <img src="docs/assets/images/collie_icon.svg" width="400px">

**CoLLiE**: **Co**llaborative Tuning of **L**arge **L**anguage Models **i**n an **E**fficient Way

</div>

## ç›®å½•
- [ç‰¹ç‚¹](#ç‰¹ç‚¹)
- [è¯„æµ‹](#è¯„æµ‹)
- [å®‰è£…](#å®‰è£…)
- [ä½¿ç”¨](#ä½¿ç”¨)
- [æ”¯æŒçš„æ¨¡å‹](#æ”¯æŒçš„æ¨¡å‹)

## è¯„æµ‹
### ååé‡
|            | 7B   | 13B  | 30B  | 65B  |
| ---------- | ---- | ---- | ---- | ---- |
| Finetune   | 2    | 3    | 6    | 16   |
| LoRA       | 1    | 1    | 1    | 2    |
| LOMO       | 1    | 1    | 1    | 2    |

æ³¨ï¼šåœ¨ä½¿ç”¨Adamä¼˜åŒ–å™¨çš„æƒ…å†µä¸‹ï¼Œå„ä¸ªæ¨¡å‹éœ€è¦çš„æœ€å°‘çš„GPUï¼ˆA100ï¼‰æ•°é‡

## ç‰¹ç‚¹
<div align="center">
    <img src="docs/assets/images/features.svg" width="800px">
</div>

CoLLiE åŸºäº *DeepSpeed* å’Œ *PyTorch*ï¼Œä¸ºå¤§å‹è¯­è¨€æ¨¡å‹æä¾›åä½œå¼å’Œé«˜æ•ˆçš„è°ƒä¼˜æ–¹æ³•ã€‚
å®ƒä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å››ä¸ªç‰¹ç‚¹ï¼š
- å¹¶è¡Œç­–ç•¥
  - æ•°æ®å¹¶è¡Œ (DP)
  - [æµæ°´çº¿å¹¶è¡Œ (PP)](https://arxiv.org/pdf/1811.06965.pdf)
  - [å¼ é‡å¹¶è¡Œ (TP)](https://arxiv.org/pdf/2104.04473.pdf)
  - [é›¶å†—ä½™ä¼˜åŒ–å™¨ (ZeRO)](https://arxiv.org/pdf/1910.02054.pdf)
- æ¨¡å‹æ¶æ„
  - [Flash Attention](https://arxiv.org/pdf/2205.14135.pdf)
- å†…å­˜é«˜æ•ˆçš„å¾®è°ƒæ–¹æ³•
  - [LOMO](https://arxiv.org/pdf/2306.09782.pdf)
  - [LoRA](https://arxiv.org/pdf/2106.09685.pdf)
- ç”¨æˆ·å‹å¥½çš„ä½¿ç”¨æ–¹å¼

CoLLiEå·²ä½¿ç”¨ *Megatron-LM* å’Œ *Flash Attention* é‡å†™æ¨¡å‹ï¼Œåªéœ€ä¿®æ”¹ ```config.dp_size```ï¼Œ```config.pp_size```ï¼Œå’Œ```config.tp_size```ï¼Œå°±èƒ½ç®€å•åœ°äº«å— 3D å¹¶è¡Œï¼ˆæ³¨æ„ï¼Œè¿™ä¸‰ä¸ªå¹¶è¡Œæ€§å°ºå¯¸çš„ä¹˜ç§¯åº”ç­‰äºGPUçš„æ•°é‡ï¼‰ã€‚
æ­¤å¤–ï¼Œæ‚¨å¯ä»¥é€šè¿‡æ›´æ”¹ ```config.use_flash``` æ¥é€‰æ‹©æ˜¯å¦ä½¿ç”¨ Flash Attentionã€‚
ä¸ºäº†æ–¹ä¾¿ç”¨æˆ·ï¼ŒCoLLiE çš„æ¨¡å‹è¿˜æ”¯æŒç±»ä¼¼äº ğŸ¤—Huggingface çš„æ–¹æ³•ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ ```model.from_pretrained()``` ä»HFåŠ è½½æƒé‡ã€‚
å¦‚æœä½ ä¸æƒ³è‡ªå·±ç¼–å†™è®­ç»ƒå¾ªç¯ï¼ŒCoLLiEæä¾›äº†ä¸€ä¸ª [è®­ç»ƒå™¨](collie/trainer/trainer.py)ã€‚ä½ éœ€è¦åšçš„åªæ˜¯æä¾›é…ç½®å’Œæ•°æ®é›†æ¥è¿›è¡Œä½ çš„è‡ªå®šä¹‰è®­ç»ƒè¿‡ç¨‹ã€‚

## ä½¿ç”¨

### æ–‡æ¡£åŠç¤ºä¾‹
CoLLiEæä¾›äº† [åœ¨çº¿æ–‡æ¡£](https://openlmlab-collie.readthedocs.io/zh_CN/latest/)ã€‚ æ›´å¤šç¤ºä¾‹å¯åœ¨ [ç¤ºä¾‹](examples) ä¸­æŸ¥çœ‹ã€‚

### å¯åŠ¨è„šæœ¬
CoLLiEæä¾›äº†ä¸ [torchrun](https://pytorch.org/docs/stable/elastic/run.html) å’Œ [slurm](https://github.com/SchedMD/slurm) çš„é›†æˆï¼Œä»¥ä¾¿åœ¨å•ä¸ªæˆ–å¤šä¸ªèŠ‚ç‚¹ä¸Šè½»æ¾å¯åŠ¨ä»»åŠ¡ã€‚

## å®‰è£…
```bash
pip install git+https://github.com/OpenLMLab/collie.git
```

## æ”¯æŒçš„æ¨¡å‹

- [MOSS-MOON](https://github.com/OpenLMLab/MOSS)
    - [moss-moon-003-base](https://huggingface.co/fnlp/moss-moon-003-base)
    - [moss-moon-003-sft](https://huggingface.co/fnlp/moss-moon-003-sft)
    - [moss-moon-003-sft-plugin](https://huggingface.co/fnlp/moss-moon-003-sft-plugin)
- [InternLM](https://github.com/InternLM/InternLM)
    - [internlm-7b](https://huggingface.co/internlm/internlm-7b)
    - [internlm-chat-7b](https://huggingface.co/internlm/internlm-chat-7b)
    - [internlm-chat-7b-8k](https://huggingface.co/internlm/internlm-chat-7b-8k)
- [LLaMA](https://github.com/facebookresearch/llama)
    - [llama-7b-hf](https://huggingface.co/decapoda-research/llama-7b-hf)
    - [llama-13b-hf](https://huggingface.co/decapoda-research/llama-13b-hf)
    - [llama-30b-hf](https://huggingface.co/decapoda-research/llama-30b-hf)
    - [llama-65b-hf](https://huggingface.co/decapoda-research/llama-65b-hf)
- [OpenLLaMA]
    - [open_llama_3b](https://huggingface.co/openlm-research/open_llama_3b)
    - [open_llama_7b](https://huggingface.co/openlm-research/open_llama_7b)
    - [open_llama_13b](https://huggingface.co/openlm-research/open_llama_13b)
    - [open_llama_7b_v2](https://huggingface.co/openlm-research/open_llama_7b_v2)
- [ChatGLM](https://github.com/THUDM/ChatGLM-6B)
    - [chatglm-6b](https://huggingface.co/THUDM/chatglm-6b)
- [ChatGLM2](https://github.com/THUDM/ChatGLM2-6B)
    - [chatglm2-6b](https://huggingface.co/THUDM/chatglm2-6b)
